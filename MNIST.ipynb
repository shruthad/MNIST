{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGQdFP0RYVVYmZQvTKu0bc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruthad/MNIST/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDgg3AgKdmZU"
      },
      "source": [
        "#importing libraries\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import keras.utils\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.model_selection import KFold\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfdlGPYcesny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d624455-297e-4f5e-f0be-c5e64f524755"
      },
      "source": [
        "#loading dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0834uMjYfFeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f122a69f-03a4-4e02-c749-5069348d2428"
      },
      "source": [
        "print(type(x_train),type(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIyw7iCfH_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9373a7-52e9-4250-d12d-b68d1528e8fb"
      },
      "source": [
        "\n",
        "#evaluate loaded dataset\n",
        "print('Dim of X train is ',x_train.shape)\n",
        "print('Dim of y train is ',y_train.shape)\n",
        "print('Dim of X test is ',x_test.shape)\n",
        "print('Dim of y test is ',y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dim of X train is  (60000, 28, 28)\n",
            "Dim of y train is  (60000,)\n",
            "Dim of X test is  (10000, 28, 28)\n",
            "Dim of y test is  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_caOLNZPfegi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1adda4-493b-4bec-c509-2fe274ad1ff1"
      },
      "source": [
        "#shape of each data\n",
        "ex_image = x_train[0]\n",
        "ex_label = y_train[0]\n",
        "\n",
        "print('Shape of ex is ',ex_image.shape)\n",
        "print('label of ex is ',ex_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of ex is  (28, 28)\n",
            "label of ex is  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUkP1PYbftU-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "4e2b6a19-1e64-4eca-c534-66e758d9c9f2"
      },
      "source": [
        "plt.imshow(ex_image,cmap=plt.cm.gray)\n",
        "plt.title('This image represents {}'.format(ex_label))\n",
        "plt.xticks([])\n",
        "plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([], <a list of 0 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqXLs8ggEIC"
      },
      "source": [
        "def show(image, title):\n",
        "    index = 1 \n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    for x in zip(image, title):        \n",
        "        image = x[0]        \n",
        "        title = x[1]\n",
        "        plt.subplot(2, 5, index)        \n",
        "        plt.imshow(image.reshape(28,28), cmap=plt.cm.gray)  \n",
        "        plt.title(x[1], fontsize = 9)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        index += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pn4lzZJgF12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "8166216f-1fee-46b9-c713-1615f21e22f4"
      },
      "source": [
        "image = []\n",
        "title = []\n",
        "for i in range(0, 5):\n",
        "    r = random.randint(1, len(x_train))\n",
        "    image.append(x_train[r])\n",
        "    title.append('training image:' + str(y_train[r]))       \n",
        "\n",
        "for i in range(0, 5):\n",
        "    r = random.randint(1, len(x_test))\n",
        "    image.append(x_test[r])\n",
        "    title.append('testing image:' + str(y_test[r]))\n",
        "    \n",
        "show(image, title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw4uSiHvgXq6"
      },
      "source": [
        "# reshape dataset to have a single channel\n",
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G5GFkglgdGM"
      },
      "source": [
        "# one hot encode target values\n",
        "y_train =  keras.utils.to_categorical(y_train)\n",
        "y_test =  keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1wszPqAgzjI"
      },
      "source": [
        "#convert from integer to float and normalize to range 0-1\n",
        "x_train = x_train.astype('float32')/255.\n",
        "x_test = x_test.astype('float32')/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsltvpTKhMGf"
      },
      "source": [
        "#cnn using Alexnet architecture\n",
        "model = Sequential()\n",
        "#This gets our neural network as sequential network\n",
        "#1st convolution layer\n",
        "model.add(Conv2D(96, (11,11),input_shape = (28,28,1), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(3, strides=2))\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(256, 5, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(3, strides=2))\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(384, 3, strides=1, padding='same', activation='relu'))\n",
        "#4th convolution layer\n",
        "model.add(Conv2D(384, 3, strides=1, padding='same', activation='relu'))\n",
        "#5th convolution layer\n",
        "model.add(Conv2D(256, 3, strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#max pooling\n",
        "model.add(MaxPooling2D(3, strides=2))\n",
        "model.add(Flatten())\n",
        "#1st fully connected layers\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "#Dropout to prevent overfitting\n",
        "#2nd fully connected layers\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "#3rd fully connected layers\n",
        "model.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGV4wTy0hvy1"
      },
      "source": [
        "#compile model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxpV08Edi5Vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a210bb9-d6a3-4451-ec86-9ffc4a81b49d"
      },
      "source": [
        "def evaluate_model(dataX, dataY, n_folds=5):\n",
        "\tscores, histories = list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\t\n",
        "\t\t# select rows for train and test\n",
        "\t\tx_train, y_train, xtest, ytest = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# stores scores\n",
        "\t\tscores.append(acc)\n",
        "\t\thistories.append(history)\n",
        "\treturn scores, histories\n",
        "scores, histories = evaluate_model(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   1/1200 [..............................] - ETA: 19s - loss: 3.7253e-08 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0160s). Check your callbacks.\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0998 - accuracy: 0.9851 - val_loss: 0.0846 - val_accuracy: 0.9846\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0933 - accuracy: 0.9838 - val_loss: 0.0404 - val_accuracy: 0.9923\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0458 - accuracy: 0.9901 - val_loss: 0.0616 - val_accuracy: 0.9886\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0433 - accuracy: 0.9910 - val_loss: 0.0377 - val_accuracy: 0.9928\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0396 - accuracy: 0.9914 - val_loss: 0.0583 - val_accuracy: 0.9881\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0658 - accuracy: 0.9890 - val_loss: 0.0462 - val_accuracy: 0.9913\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0400 - accuracy: 0.9924 - val_loss: 0.0355 - val_accuracy: 0.9939\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 0.0397 - val_accuracy: 0.9933\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 0.0300 - val_accuracy: 0.9942\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0265 - accuracy: 0.9947 - val_loss: 0.0395 - val_accuracy: 0.9943\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.0600 - val_accuracy: 0.9890\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0261 - accuracy: 0.9950 - val_loss: 0.0415 - val_accuracy: 0.9949\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 0.0417 - val_accuracy: 0.9952\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0274 - accuracy: 0.9955 - val_loss: 0.0302 - val_accuracy: 0.9947\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.0622 - val_accuracy: 0.9918\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0264 - accuracy: 0.9952 - val_loss: 0.0394 - val_accuracy: 0.9946\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.0412 - val_accuracy: 0.9947\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0450 - val_accuracy: 0.9940\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0200 - accuracy: 0.9962 - val_loss: 0.0267 - val_accuracy: 0.9961\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 29s 24ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 0.0866 - val_accuracy: 0.9913\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0949 - accuracy: 0.9890\n",
            "> 98.900\n",
            "Epoch 1/20\n",
            "   1/1200 [..............................] - ETA: 14s - loss: 0.0013 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0149s). Check your callbacks.\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9935WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0392 - accuracy: 0.9935 - val_loss: 0.0510 - val_accuracy: 0.9911\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0235 - accuracy: 0.9951 - val_loss: 0.0620 - val_accuracy: 0.9878\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.0622 - val_accuracy: 0.9926\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.0622 - val_accuracy: 0.9907\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0653 - val_accuracy: 0.9911\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.0699 - val_accuracy: 0.9910\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0200 - accuracy: 0.9965 - val_loss: 0.0574 - val_accuracy: 0.9906\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0894 - val_accuracy: 0.9909\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 0.0904 - val_accuracy: 0.9927\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0119 - accuracy: 0.9978 - val_loss: 0.0588 - val_accuracy: 0.9900\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0702 - val_accuracy: 0.9911\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0203 - accuracy: 0.9972 - val_loss: 0.1001 - val_accuracy: 0.9921\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.0685 - val_accuracy: 0.9900\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 25s 20ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.0855 - val_accuracy: 0.9906\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.1210 - val_accuracy: 0.9931\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0751 - val_accuracy: 0.9928\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0914 - val_accuracy: 0.9924\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0768 - val_accuracy: 0.9919\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0147 - accuracy: 0.9977 - val_loss: 0.0668 - val_accuracy: 0.9918\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0191 - accuracy: 0.9982 - val_loss: 0.0834 - val_accuracy: 0.9915\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0735 - accuracy: 0.9926\n",
            "> 99.260\n",
            "Epoch 1/20\n",
            "   1/1200 [..............................] - ETA: 17s - loss: 2.1234e-07 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0146s). Check your callbacks.\n",
            "1198/1200 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9965WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_test_batch_end` time: 0.0042s). Check your callbacks.\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0233 - accuracy: 0.9965 - val_loss: 0.0987 - val_accuracy: 0.9914\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0675 - val_accuracy: 0.9927\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1007 - val_accuracy: 0.9919\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 25s 20ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.0869 - val_accuracy: 0.9905\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0173 - accuracy: 0.9975 - val_loss: 0.0869 - val_accuracy: 0.9903\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0817 - val_accuracy: 0.9916\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.1116 - val_accuracy: 0.9899\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0763 - val_accuracy: 0.9933\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0878 - val_accuracy: 0.9908\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.1205 - val_accuracy: 0.9887\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 3.8401 - val_accuracy: 0.9904\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 0.1314 - val_accuracy: 0.9902\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 8.0993 - val_accuracy: 0.9924\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.1083 - val_accuracy: 0.9915\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.1907 - val_accuracy: 0.9903\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.1221 - val_accuracy: 0.9919\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.1003 - val_accuracy: 0.9925\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.1104 - val_accuracy: 0.9916\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.0950 - val_accuracy: 0.9933\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.1269 - val_accuracy: 0.9910\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0978 - accuracy: 0.9930\n",
            "> 99.300\n",
            "Epoch 1/20\n",
            "   1/1200 [..............................] - ETA: 18s - loss: 8.5682e-08 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.0151s). Check your callbacks.\n",
            "1200/1200 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9981WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_test_batch_end` time: 0.0035s). Check your callbacks.\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.0696 - val_accuracy: 0.9925\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0977 - val_accuracy: 0.9917\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.0866 - val_accuracy: 0.9933\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.1091 - val_accuracy: 0.9905\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.0840 - val_accuracy: 0.9931\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.1016 - val_accuracy: 0.9926\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0969 - val_accuracy: 0.9929\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1185 - val_accuracy: 0.9935\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.1413 - val_accuracy: 0.9920\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.1122 - val_accuracy: 0.9923\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.0914 - val_accuracy: 0.9928\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0733 - val_accuracy: 0.9932\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2143 - val_accuracy: 0.9923\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 0.1190 - val_accuracy: 0.9911\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1249 - val_accuracy: 0.9925\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.1356 - val_accuracy: 0.9933\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.1123 - val_accuracy: 0.9922\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1035 - val_accuracy: 0.9930\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2133 - val_accuracy: 0.9907\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.2220 - val_accuracy: 0.9933\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1289 - accuracy: 0.9938\n",
            "> 99.380\n",
            "Epoch 1/20\n",
            "   1/1200 [..............................] - ETA: 18s - loss: 0.0000e+00 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0150s). Check your callbacks.\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0226 - accuracy: 0.9976 - val_loss: 0.0963 - val_accuracy: 0.9930\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 25s 20ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.2155 - val_accuracy: 0.9935\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 3.2037 - val_accuracy: 0.9932\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.1303 - val_accuracy: 0.9931\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 0.0835 - val_accuracy: 0.9949\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 0.0729 - val_accuracy: 0.9937\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0988 - val_accuracy: 0.9942\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.6067 - val_accuracy: 0.9930\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 2.7516 - val_accuracy: 0.9925\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 2.2527 - val_accuracy: 0.9917\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0124 - accuracy: 0.9986 - val_loss: 0.2656 - val_accuracy: 0.9929\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 10.6145 - val_accuracy: 0.9935\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.7274 - val_accuracy: 0.9945\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0165 - accuracy: 0.9984 - val_loss: 0.1214 - val_accuracy: 0.9911\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.2859 - val_accuracy: 0.9919\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.1446 - val_accuracy: 0.9933\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.6243 - val_accuracy: 0.9935\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.1321 - val_accuracy: 0.9925\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 2.2058 - val_accuracy: 0.9926\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 24s 20ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.2957 - val_accuracy: 0.9894\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.3214 - accuracy: 0.9908\n",
            "> 99.080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "fcLBgPA73tJs",
        "outputId": "01683a4b-e296-4c53-e0c3-0f9401971723"
      },
      "source": [
        "\n",
        "# summarize model performance\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "def summarize_performance(scores):\n",
        "\t# print summary\n",
        "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "\t# box and whisker plots of results\n",
        "\tpyplot.boxplot(scores)\n",
        "\tpyplot.show()\n",
        "\t# summarize estimated performance\n",
        "summarize_performance(scores)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: mean=99.184 std=0.173, n=5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E8DncA14Xqa"
      },
      "source": [
        "model.save(\"final_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXBJzJmS41SY",
        "outputId": "47f784ff-de37-49db-b3ff-b32bcf450bac"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 18, 18, 96)        11712     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 18, 18, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 3, 3, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 21,601,354\n",
            "Trainable params: 21,600,138\n",
            "Non-trainable params: 1,216\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VDpf5Qa77xZ",
        "outputId": "f368e8d6-881b-4195-ccf2-eec2cc7ff34c"
      },
      "source": [
        "import numpy as np\n",
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('sample_image.png')\n",
        "\t# load model\n",
        "\tmodel = load_model(\"final_model.h5\")\n",
        "\t# predict the class\n",
        "\tdigit =model.predict_classes(img)\n",
        "\tprint(digit[0])\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-8035d5e31103>:27: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm4V0bVhQQMl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}